# 一次爬虫实践

## 简单爬虫框架：

用到的库

```python
import urllib3
from bs4 import BeautifulSoup
import certifi
```

配置爬虫

```python
headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'}
url='https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/content/116.html'
http = urllib3.PoolManager(10,cert_reqs='CERT_REQUIRED',ca_certs=certifi.where())
req=http.request('get',url,headers=headers)
```

这样就拿到了网站的返回数据,得到一个`urllib3.response.HTTPResponse`对象，网站的源代码就存放在`req.data`中

接下来我们利用BeautifulSoup库来进一步处理,`BeautifulSoup`里有两个好用的函数`BeautifulSoup.find()`以及`BeautifulSoup.find_all()`

```python
soup=BeautifulSoup(req.data.decode('utf-8'))
soup.find('div')
soup.find_all('div',class_='page-inner')
```

`BeautifulSoup.find()`返回的是一个tag对象

#### tag

tag拥有两个重要属性：name, attrs

1. name即是tag的名字，例如`soup.find('p')`或者`soup.p`得到的tag的名字就是'p'

2. attrs是tag的相关属性，在html里就是`<tag>`里封装的一些属性，例如

```
<div 
class="book" 
data-chapter-title="1.2 Torvalds的Linux发展">
```



#### 点操作以及find()

点操作或者find()只能获取符合要求的第一个tag



其中`BeautifulSoup.find_all()`返回的是一个iterator,可以通过`for`语句操作

```python
for p in soup.find_all():
    print(p.text)
```





